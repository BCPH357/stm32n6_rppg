# æœå‹™å™¨ç«¯ INT8 é‡åŒ– - å¿«é€Ÿé–‹å§‹æŒ‡å—

æ‰€æœ‰æ–‡ä»¶å·²ä¸Šå‚³åˆ°æœå‹™å™¨ï¼ç¾åœ¨å¯ä»¥ç›´æ¥åœ¨æœå‹™å™¨ä¸ŠåŸ·è¡Œé‡åŒ–æµç¨‹ã€‚

---

## âœ… å·²å®Œæˆ

- [x] æ‰€æœ‰ Python è…³æœ¬å·²ä¸Šå‚³
- [x] åŸ·è¡Œè…³æœ¬ `run_quantization.sh` å·²ä¸Šå‚³ä¸¦è¨­ç½®æ¬Šé™
- [x] æ–‡æª”å·²ä¸Šå‚³
- [x] æ¨¡å‹è¨“ç·´å·²å®Œæˆï¼ˆ`best_model.pth` å­˜åœ¨ï¼‰
- [x] è¨“ç·´æ•¸æ“šå·²æº–å‚™ï¼ˆ`ubfc_processed.pt` å­˜åœ¨ï¼‰

---

## ğŸš€ åŸ·è¡Œæ­¥é©Ÿï¼ˆæœå‹™å™¨ç«¯ï¼‰

### Step 1: SSH é€£æ¥åˆ°æœå‹™å™¨

```bash
ssh miat@140.115.53.67
```

### Step 2: é€²å…¥é‡åŒ–ç›®éŒ„

```bash
cd /mnt/data_8T/ChenPinHao/server_training/quantization
```

### Step 3: å®‰è£ ONNX ä¾è³´

```bash
conda activate rppg_training
pip install -r requirements_server.txt
```

é æœŸè¼¸å‡ºï¼š
```
Collecting onnx>=1.19.0
Collecting onnxruntime>=1.23.0
...
Successfully installed onnx-1.19.1 onnxruntime-1.23.2
```

### Step 4: åŸ·è¡Œé‡åŒ–æµç¨‹

```bash
bash run_quantization.sh
```

**æµç¨‹èªªæ˜**ï¼š
1. æº–å‚™æ ¡æº–æ•¸æ“šï¼ˆ200 samplesï¼Œ~2 åˆ†é˜ï¼‰
2. å°å‡º FP32 ONNXï¼ˆ~30 ç§’ï¼‰
3. INT8 é‡åŒ–ï¼ˆ~3-5 åˆ†é˜ï¼‰
4. é©—è­‰ç²¾åº¦ï¼ˆ500 samplesï¼Œ~2 åˆ†é˜ï¼‰

**ç¸½æ™‚é–“**ï¼šç´„ 10-15 åˆ†é˜

### Step 5: æª¢æŸ¥çµæœ

é‡åŒ–å®Œæˆå¾Œï¼Œæª¢æŸ¥ç”Ÿæˆçš„æ–‡ä»¶ï¼š

```bash
ls -lh models/
```

é æœŸè¼¸å‡ºï¼š
```
rppg_fp32.onnx       # FP32 æ¨¡å‹ï¼ˆ~80 KBï¼‰
rppg_int8_qdq.onnx   # INT8 é‡åŒ–æ¨¡å‹ï¼ˆ~20 KBï¼‰â† ç”¨æ–¼éƒ¨ç½²
```

### Step 6: ä¸‹è¼‰é‡åŒ–æ¨¡å‹ï¼ˆæœ¬åœ°åŸ·è¡Œï¼‰

åœ¨æœ¬åœ° Windows PowerShell åŸ·è¡Œï¼š

```powershell
scp miat@140.115.53.67:/mnt/data_8T/ChenPinHao/server_training/quantization/models/rppg_int8_qdq.onnx D:\MIAT\rppg\quantization\models\
```

---

## ğŸ“Š é æœŸçµæœ

å¦‚æœé‡åŒ–æˆåŠŸï¼Œæ‡‰è©²çœ‹åˆ°é¡ä¼¼è¼¸å‡ºï¼š

```
==================================================================
Quantization Workflow Completed!
==================================================================

âœ… Status: SUCCESS - Quantization acceptable

Next steps:
1. Download INT8 model: models/rppg_int8_qdq.onnx
2. Use X-CUBE-AI to convert for STM32N6
3. Refer to: ../stm32n6_deployment/deployment_guide.md

==================================================================
```

**é—œéµæŒ‡æ¨™**ï¼š
- MAE å¢åŠ  < 2.0 BPMï¼ˆå¯æ¥å—ï¼‰
- æ¨¡å‹å¤§å°ï¼šFP32 ~80 KB â†’ INT8 ~20 KBï¼ˆ4x å£“ç¸®ï¼‰
- ç²¾åº¦æå¤±ï¼šMAE +1.0~1.5 BPMï¼ˆé æœŸç¯„åœï¼‰

---

## âš ï¸ å¦‚æœé‡åˆ°å•é¡Œ

### å•é¡Œ 1: æ‰¾ä¸åˆ°è¨“ç·´æ•¸æ“š

```bash
# æª¢æŸ¥æ•¸æ“šæ˜¯å¦å­˜åœ¨
ls -l /mnt/data_8T/ChenPinHao/server_training/data/ubfc_processed.pt
```

å¦‚æœä¸å­˜åœ¨ï¼Œéœ€è¦é‡æ–°é è™•ç†ï¼š
```bash
cd /mnt/data_8T/ChenPinHao/server_training/
python preprocess_data.py --dataset ubfc --raw_data raw_data --output data
```

### å•é¡Œ 2: ONNX å®‰è£å¤±æ•—

```bash
# æ‰‹å‹•å®‰è£
conda activate rppg_training
pip install onnx==1.19.1 onnxruntime==1.23.2
```

### å•é¡Œ 3: é‡åŒ–ç²¾åº¦ä¸è¶³

å¦‚æœé©—è­‰é¡¯ç¤º MAE å¢åŠ  >= 2.0 BPMï¼š

```bash
# å¢åŠ æ ¡æº–æ¨£æœ¬æ•¸é‡åˆ° 500
python quantize_utils.py --data ../data/ubfc_processed.pt --num_samples 500
python quantize_onnx.py
python verify_quantization.py
```

### å•é¡Œ 4: æ¬Šé™éŒ¯èª¤

```bash
# è¨­ç½®åŸ·è¡Œæ¬Šé™
chmod +x run_quantization.sh
```

---

## ğŸ“ æœå‹™å™¨ç›®éŒ„çµæ§‹

```
/mnt/data_8T/ChenPinHao/server_training/
â”œâ”€â”€ quantization/                  â† æ–°å¢çš„é‡åŒ–ç›®éŒ„
â”‚   â”œâ”€â”€ quantize_utils.py          â† æ ¡æº–æ•¸æ“šæº–å‚™
â”‚   â”œâ”€â”€ export_onnx.py             â† ONNX å°å‡º
â”‚   â”œâ”€â”€ quantize_onnx.py           â† INT8 é‡åŒ–
â”‚   â”œâ”€â”€ verify_quantization.py     â† ç²¾åº¦é©—è­‰
â”‚   â”œâ”€â”€ run_quantization.sh        â† åŸ·è¡Œè…³æœ¬
â”‚   â”œâ”€â”€ README_SERVER.md           â† è©³ç´°æ–‡æª”
â”‚   â”œâ”€â”€ requirements_server.txt    â† ä¾è³´æ¸…å–®
â”‚   â””â”€â”€ models/                    â† ç”Ÿæˆçš„æ¨¡å‹ï¼ˆåŸ·è¡Œå¾Œï¼‰
â”‚       â”œâ”€â”€ rppg_fp32.onnx
â”‚       â””â”€â”€ rppg_int8_qdq.onnx
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ubfc_processed.pt          â† è¨“ç·´æ•¸æ“šï¼ˆå·²å­˜åœ¨ï¼‰
â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ best_model.pth             â† è¨“ç·´æ¨¡å‹ï¼ˆå·²å­˜åœ¨ï¼‰
â”œâ”€â”€ model.py
â”œâ”€â”€ train.py
â””â”€â”€ ...
```

---

## ğŸ¯ ä¸‹ä¸€æ­¥ï¼ˆé‡åŒ–å®Œæˆå¾Œï¼‰

1. **ä¸‹è¼‰ INT8 æ¨¡å‹**ï¼š`models/rppg_int8_qdq.onnx`
2. **ä½¿ç”¨ X-CUBE-AI è½‰æ›**ï¼šåƒè€ƒ `D:\MIAT\rppg\stm32n6_deployment\deployment_guide.md`
3. **éƒ¨ç½²åˆ° STM32N6**ï¼šä½¿ç”¨ O1 æˆ– O2 å„ªåŒ–ï¼ˆé¿å… O3ï¼ï¼‰
4. **é©—è­‰æ¨è«–**ï¼šåœ¨ç¡¬ä»¶ä¸Šæ¸¬è©¦å¿ƒç‡æª¢æ¸¬

---

## ğŸ“– æ›´å¤šè³‡æº

- **è©³ç´°é‡åŒ–æ–‡æª”**: `README_SERVER.md`ï¼ˆæœå‹™å™¨ç«¯ï¼‰æˆ– `README.md`ï¼ˆæœ¬åœ°ï¼‰
- **STM32N6 éƒ¨ç½²æŒ‡å—**: `D:\MIAT\rppg\stm32n6_deployment\deployment_guide.md`
- **æ•…éšœæ’é™¤**: `D:\MIAT\rppg\stm32n6_deployment\troubleshooting.md`
- **é …ç›®è¨˜éŒ„**: `D:\MIAT\rppg\CLAUDE.md`

---

**æº–å‚™å¥½äº†å—ï¼Ÿ** ç¾åœ¨å°±å¯ä»¥åœ¨æœå‹™å™¨ä¸ŠåŸ·è¡Œ `bash run_quantization.sh` é–‹å§‹é‡åŒ–ï¼

---

**ç‰ˆæœ¬**: 1.0
**å‰µå»ºæ—¥æœŸ**: 2025-01-20
**æœ€å¾Œæ›´æ–°**: 2025-01-20
