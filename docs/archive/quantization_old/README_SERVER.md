# æœå‹™å™¨ç«¯ INT8 é‡åŒ–æŒ‡å—

æœ¬æŒ‡å—èªªæ˜å¦‚ä½•åœ¨æœå‹™å™¨ (`miat@140.115.53.67`) ä¸ŠåŸ·è¡Œ rPPG æ¨¡å‹çš„ INT8 é‡åŒ–ã€‚

---

## ğŸ“‹ å‰ç½®æ¢ä»¶

### 1. è¨“ç·´å®Œæˆ

ç¢ºä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨æ–¼æœå‹™å™¨ä¸Šï¼š

```bash
/mnt/data_8T/ChenPinHao/server_training/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ubfc_processed.pt          # è¨“ç·´æ•¸æ“šï¼ˆå¿…é ˆï¼‰
â””â”€â”€ checkpoints/
    â””â”€â”€ best_model.pth              # è¨“ç·´å¥½çš„æ¨¡å‹ï¼ˆå¿…é ˆï¼‰
```

### 2. æª¢æŸ¥è¨“ç·´ç‹€æ…‹

```bash
ssh miat@140.115.53.67
cd /mnt/data_8T/ChenPinHao/server_training/

# æª¢æŸ¥æ•¸æ“šæ–‡ä»¶
ls -lh data/ubfc_processed.pt

# æª¢æŸ¥æ¨¡å‹æ–‡ä»¶
ls -lh checkpoints/best_model.pth

# æŸ¥çœ‹è¨“ç·´æ—¥èªŒï¼ˆç¢ºèª MAE < 10 BPMï¼‰
tail -50 logs/training_*.log
```

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

### Step 1: å®‰è£ ONNX ä¾è³´

```bash
cd /mnt/data_8T/ChenPinHao/server_training/quantization
conda activate rppg_training
pip install -r requirements_server.txt
```

**é æœŸè¼¸å‡º**ï¼š
```
Successfully installed onnx-1.19.1 onnxruntime-1.23.2
```

### Step 2: åŸ·è¡Œé‡åŒ–æµç¨‹

```bash
bash run_quantization.sh
```

**æµç¨‹èªªæ˜**ï¼š
1. **æº–å‚™æ ¡æº–æ•¸æ“š**ï¼ˆ~2 åˆ†é˜ï¼‰- å¾è¨“ç·´æ•¸æ“šä¸­æå– 200 å€‹æ¨£æœ¬
2. **å°å‡º FP32 ONNX**ï¼ˆ~30 ç§’ï¼‰- å°‡ PyTorch æ¨¡å‹è½‰æ›ç‚º ONNX
3. **INT8 é‡åŒ–**ï¼ˆ~3-5 åˆ†é˜ï¼‰- ä½¿ç”¨ ONNX Runtime é€²è¡Œé‡åŒ–
4. **é©—è­‰ç²¾åº¦**ï¼ˆ~2 åˆ†é˜ï¼‰- å°æ¯” FP32 vs INT8 æ€§èƒ½

**ç¸½æ™‚é–“**ï¼šç´„ 10-15 åˆ†é˜

### Step 3: ä¸‹è¼‰é‡åŒ–æ¨¡å‹

```bash
# åœ¨æœ¬åœ°åŸ·è¡Œï¼ˆWindows PowerShellï¼‰
scp miat@140.115.53.67:/mnt/data_8T/ChenPinHao/server_training/quantization/models/rppg_int8_qdq.onnx D:\MIAT\rppg\quantization\models\
```

---

## ğŸ“Š é æœŸçµæœ

### æˆåŠŸæ¡ˆä¾‹

```
==================================================================
[Step 4/4] Verifying Quantization Accuracy
==================================================================

ğŸ“Š FP32 Model Performance:
   MAE:  4.65 BPM
   RMSE: 6.63 BPM

ğŸ“Š INT8 Model Performance:
   MAE:  6.12 BPM
   RMSE: 8.01 BPM

ğŸ“ˆ Quantization Impact:
   MAE increase:  +1.47 BPM (+31.61%)
   RMSE increase: +1.38 BPM (+20.81%)

âœ… Quantization ACCEPTABLE
   MAE increase (1.47 BPM) < threshold (2.0 BPM)

==================================================================
Quantization Workflow Completed!
==================================================================

âœ… Status: SUCCESS - Quantization acceptable

Next steps:
1. Download INT8 model: models/rppg_int8_qdq.onnx
2. Use X-CUBE-AI to convert for STM32N6
3. Refer to: ../stm32n6_deployment/deployment_guide.md
```

### è¼¸å‡ºæ–‡ä»¶

```
quantization/
â”œâ”€â”€ calibration_data.pt           # æ ¡æº–æ•¸æ“šï¼ˆ~50-100 MBï¼‰
â””â”€â”€ models/
    â”œâ”€â”€ rppg_fp32.onnx            # FP32 ONNXï¼ˆ~80 KBï¼‰
    â””â”€â”€ rppg_int8_qdq.onnx        # INT8 ONNXï¼ˆ~20 KBï¼‰âœ¨ ç”¨æ–¼éƒ¨ç½²
```

---

## âš ï¸ æ•…éšœæ’é™¤

### å•é¡Œ 1: æ‰¾ä¸åˆ°è¨“ç·´æ•¸æ“š

**éŒ¯èª¤**ï¼š
```
âŒ Error: Data file not found at ../data/ubfc_processed.pt
```

**è§£æ±º**ï¼š
```bash
# æª¢æŸ¥æ•¸æ“šè·¯å¾‘
ls -l /mnt/data_8T/ChenPinHao/server_training/data/ubfc_processed.pt

# å¦‚æœä¸å­˜åœ¨ï¼Œé‡æ–°é è™•ç†
cd /mnt/data_8T/ChenPinHao/server_training/
python preprocess_data.py --dataset ubfc --raw_data raw_data --output data
```

---

### å•é¡Œ 2: æ‰¾ä¸åˆ°è¨“ç·´æ¨¡å‹

**éŒ¯èª¤**ï¼š
```
âŒ Error: Checkpoint not found at ../checkpoints/best_model.pth
```

**è§£æ±º**ï¼š
```bash
# æª¢æŸ¥æ¨¡å‹è·¯å¾‘
ls -l /mnt/data_8T/ChenPinHao/server_training/checkpoints/

# å¦‚æœä¸å­˜åœ¨æˆ–è¨“ç·´æœªå®Œæˆï¼Œé‡æ–°è¨“ç·´
cd /mnt/data_8T/ChenPinHao/server_training/
bash start_training_background.sh
```

---

### å•é¡Œ 3: ONNX å¥—ä»¶æœªå®‰è£

**éŒ¯èª¤**ï¼š
```
ModuleNotFoundError: No module named 'onnx'
```

**è§£æ±º**ï¼š
```bash
conda activate rppg_training
pip install onnx onnxruntime
```

---

### å•é¡Œ 4: é‡åŒ–ç²¾åº¦ä¸è¶³

**éŒ¯èª¤**ï¼š
```
âš ï¸ Quantization DEGRADATION SIGNIFICANT
   MAE increase (3.2 BPM) >= threshold (2.0 BPM)
```

**è§£æ±ºæ–¹æ¡ˆ A - å¢åŠ æ ¡æº–æ¨£æœ¬**ï¼š
```bash
python quantize_utils.py --data ../data/ubfc_processed.pt \
                         --output calibration_data.pt \
                         --num_samples 500

python quantize_onnx.py
python verify_quantization.py
```

**è§£æ±ºæ–¹æ¡ˆ B - æª¢æŸ¥è¨“ç·´æ¨¡å‹**ï¼š
```bash
# ç¢ºèªè¨“ç·´æ¨¡å‹æœ¬èº«çš„æ€§èƒ½
python -c "
import torch
checkpoint = torch.load('checkpoints/best_model.pth')
print(f'Validation MAE: {checkpoint.get(\"val_mae\", \"N/A\")} BPM')
print(f'Epoch: {checkpoint.get(\"epoch\", \"N/A\")}')
"
```

å¦‚æœè¨“ç·´ MAE > 10 BPMï¼Œé‡åŒ–å¾Œå¿…ç„¶ä¸ä½³ï¼Œéœ€è¦é‡æ–°è¨“ç·´ã€‚

---

## ğŸ“ ç›®éŒ„çµæ§‹

å®Œæˆå¾Œï¼Œæœå‹™å™¨ä¸Šçš„ç›®éŒ„çµæ§‹å¦‚ä¸‹ï¼š

```
/mnt/data_8T/ChenPinHao/server_training/
â”œâ”€â”€ quantization/                  # é‡åŒ–è…³æœ¬ï¼ˆæ–°å¢ï¼‰
â”‚   â”œâ”€â”€ run_quantization.sh        # åŸ·è¡Œè…³æœ¬
â”‚   â”œâ”€â”€ quantize_utils.py          # æ ¡æº–æ•¸æ“šæº–å‚™
â”‚   â”œâ”€â”€ export_onnx.py             # ONNX å°å‡º
â”‚   â”œâ”€â”€ quantize_onnx.py           # INT8 é‡åŒ–
â”‚   â”œâ”€â”€ verify_quantization.py     # ç²¾åº¦é©—è­‰
â”‚   â”œâ”€â”€ requirements_server.txt    # ä¾è³´æ¸…å–®
â”‚   â”œâ”€â”€ calibration_data.pt        # æ ¡æº–æ•¸æ“šï¼ˆç”Ÿæˆï¼‰
â”‚   â””â”€â”€ models/                    # æ¨¡å‹è¼¸å‡ºï¼ˆç”Ÿæˆï¼‰
â”‚       â”œâ”€â”€ rppg_fp32.onnx
â”‚       â””â”€â”€ rppg_int8_qdq.onnx     # æœ€çµ‚ç”¢ç‰©
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ubfc_processed.pt          # è¨“ç·´æ•¸æ“šï¼ˆå·²å­˜åœ¨ï¼‰
â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ best_model.pth             # è¨“ç·´æ¨¡å‹ï¼ˆå·²å­˜åœ¨ï¼‰
â”œâ”€â”€ preprocess_data.py
â”œâ”€â”€ train.py
â”œâ”€â”€ model.py
â””â”€â”€ ...
```

---

## ğŸ”§ æ‰‹å‹•åŸ·è¡Œï¼ˆDebug ç”¨ï¼‰

å¦‚æœè‡ªå‹•è…³æœ¬å¤±æ•—ï¼Œå¯ä»¥æ‰‹å‹•é€æ­¥åŸ·è¡Œï¼š

```bash
cd /mnt/data_8T/ChenPinHao/server_training/quantization
conda activate rppg_training

# Step 1: æ ¡æº–æ•¸æ“š
python quantize_utils.py --data ../data/ubfc_processed.pt

# Step 2: å°å‡º FP32 ONNX
python export_onnx.py --checkpoint ../checkpoints/best_model.pth

# Step 3: INT8 é‡åŒ–
python quantize_onnx.py

# Step 4: é©—è­‰ç²¾åº¦
python verify_quantization.py --data ../data/ubfc_processed.pt
```

---

## ğŸ“– åƒè€ƒè³‡æº

- **å®Œæ•´é‡åŒ–æ–‡æª”**: `README.md`ï¼ˆæœ¬ç›®éŒ„ï¼‰
- **STM32N6 éƒ¨ç½²æŒ‡å—**: `../stm32n6_deployment/deployment_guide.md`
- **é …ç›®è¨˜éŒ„**: `../CLAUDE.md`

---

**ç‰ˆæœ¬**: 1.0
**å‰µå»ºæ—¥æœŸ**: 2025-01-20
**ç¶­è­·è€…**: Claude Code AI
