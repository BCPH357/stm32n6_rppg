# éƒ¨ç½² 4D rPPG æ¨¡å‹åˆ° STM32N6 çš„å®Œæ•´æµç¨‹

## å•é¡ŒèƒŒæ™¯

**å•é¡Œ**: X-CUBE-AI åªæ”¯æŒæœ€å¤š 4D å¼µé‡ï¼Œä½†æˆ‘å€‘çš„æ¨¡å‹è¼¸å…¥æ˜¯ 6D
- âŒ åŸå§‹è¼¸å…¥: `(B, 8, 3, 36, 36, 3)` = 6D
- âœ… ä¿®æ”¹å¾Œè¼¸å…¥: `(B, 72, 36, 36)` = 4D (åˆä½µ TÃ—ROIÃ—C åˆ° channel ç¶­åº¦)

**é—œéµé»**:
- âœ… **ä¸éœ€è¦é‡æ–°è¨“ç·´** - åªæ˜¯è¼¸å…¥å½¢ç‹€ä¸åŒï¼Œæ¬Šé‡å®Œå…¨ç›¸åŒ
- âœ… **éœ€è¦é‡æ–°å°å‡º ONNX** - å¾ 6D è¼¸å…¥æ”¹ç‚º 4D è¼¸å…¥
- âœ… **éœ€è¦é‡æ–°é‡åŒ–** - åŸºæ–¼æ–°çš„ 4D ONNX æ¨¡å‹

---

## Step 1: ä¸Šå‚³æ–‡ä»¶åˆ°æœå‹™å™¨

```bash
# ä¸Šå‚³è½‰æ›è…³æœ¬
scp "D:\MIAT\rppg\server_training\convert_to_4d_for_stm32.py" miat@140.115.53.67:/mnt/data_8T/ChenPinHao/server_training/

# ä¸Šå‚³é‡åŒ–è…³æœ¬
scp "D:\MIAT\rppg\server_training\quantize_4d_model.py" miat@140.115.53.67:/mnt/data_8T/ChenPinHao/server_training/
```

---

## Step 2: åœ¨æœå‹™å™¨ä¸ŠåŸ·è¡Œè½‰æ›

```bash
# é€£æ¥åˆ°æœå‹™å™¨
ssh miat@140.115.53.67

# é€²å…¥å·¥ä½œç›®éŒ„
cd /mnt/data_8T/ChenPinHao/server_training/

# æ¿€æ´»ç’°å¢ƒ
conda activate rppg_training

# åŸ·è¡Œè½‰æ›ï¼ˆ6D â†’ 4D ONNX FP32ï¼‰
python convert_to_4d_for_stm32.py
```

**é æœŸè¼¸å‡º**:
```
======================================================================
Convert 6D Model to 4D ONNX for STM32 (Server-Side)
======================================================================

[Step 1] Loading trained 6D model...
   [OK] Loaded: checkpoints/best_model.pth
   Parameters: 20,193

[Step 2] Creating 4D model (shared weights)...
   [OK] 4D model created

[Step 3] Verifying equivalence...
   6D output: 72.3456 BPM
   4D output: 72.3456 BPM
   Difference: 0.000001 BPM
   [OK] Models are equivalent

[Step 4] Exporting to ONNX...
   [OK] Exported: models/rppg_4d_fp32.onnx

[Step 5] Verifying ONNX...
   Input shape: [0, 72, 36, 36] (batch=0 means dynamic)
   Output shape: [0, 1]
   [OK] ONNX validation passed

======================================================================
[SUCCESS] Conversion Complete!
======================================================================
```

---

## Step 3: é‡åŒ–ç‚º INT8

```bash
# ä»åœ¨æœå‹™å™¨ä¸Š
cd /mnt/data_8T/ChenPinHao/server_training/

# å®‰è£ä¾è³´ï¼ˆå¦‚æœé‚„æ²’å®‰è£ï¼‰
pip install onnxruntime onnx

# åŸ·è¡Œé‡åŒ–
python quantize_4d_model.py
```

**é æœŸè¼¸å‡º**:
```
======================================================================
Quantize 4D Model to INT8 for STM32
======================================================================

[Input] models/rppg_4d_fp32.onnx
   Size: 80.50 KB

[Method 2] Static Quantization (Recommended)...
   Generating 200 calibration samples...
   [OK] Calibration data ready: 200 samples
   [OK] Saved: models/rppg_4d_int8.onnx

[Verification] Comparing FP32 vs INT8...
   Mean Absolute Error: 1.23 BPM
   Max Absolute Error:  3.45 BPM
   [OK] Quantization quality: GOOD (MAE < 5 BPM)

======================================================================
[SUCCESS] Quantization Complete!
======================================================================

Model sizes:
   FP32: 80.50 KB
   INT8: 22.30 KB
   Compression: 3.61x

Quantization error:
   Mean: 1.23 BPM
   Max:  3.45 BPM
```

---

## Step 4: ä¸‹è¼‰åˆ°æœ¬åœ°

```bash
# åœ¨æœ¬åœ° Windows åŸ·è¡Œ
scp miat@140.115.53.67:/mnt/data_8T/ChenPinHao/server_training/models/rppg_4d_int8.onnx D:\MIAT\rppg\
```

---

## Step 5: å°å…¥åˆ° STM32CubeMX

### 5.1 æ‰“é–‹ X-CUBE-AI

1. æ‰“é–‹ STM32CubeMX
2. è¼‰å…¥ä½ çš„ STM32N6 é …ç›®ï¼ˆæˆ–å‰µå»ºæ–°é …ç›®ï¼‰
3. åœ¨å·¦å´å°èˆªæ¬„é¸æ“‡ **Software Packs** â†’ **Select Components**
4. å•Ÿç”¨ **X-CUBE-AI**

### 5.2 æ·»åŠ æ¨¡å‹

1. åœ¨ X-CUBE-AI é…ç½®é é¢ï¼Œé»æ“Š **Add network**
2. é¸æ“‡ `D:\MIAT\rppg\rppg_4d_int8.onnx`
3. é»æ“Š **Analyze**

### 5.3 é…ç½®åƒæ•¸ï¼ˆé‡è¦ï¼ï¼‰

**åŸºæ–¼ Zero-DCE å¤±æ•—ç¶“é©—çš„é—œéµé…ç½®**:

| åƒæ•¸ | æ¨è–¦å€¼ | èªªæ˜ |
|------|-------|------|
| **Optimization** | **Time (O2)** æˆ– **Default (O1)** | âœ… ç©©å®š |
| **Optimization** | ~~Balanced (O3)~~ | âŒ **é¿å…ä½¿ç”¨ï¼æœƒå°è‡´ç·©è¡å€é‡ç–Š** |
| **Compression** | None æˆ– Lossless | å¯é¸ |
| **Runtime** | Neural-ART | STM32N6 NPU |
| **Memory Pools** | Auto | è®“å·¥å…·è‡ªå‹•åˆ†é… |

**ç‚ºä»€éº¼é¿å… O3ï¼Ÿ**
- å°è‡´æ¿€é€²çš„å…§å­˜é‡ç”¨å’Œç·©è¡å€é‡ç–Š
- æ¨è«–ç¬¬ä¸€æ¬¡èª¿ç”¨å°±è¿”å› `LL_ATON_RT_ERROR`
- æ‰€æœ‰æ‰‹å‹•ä¿®å¾©å˜—è©¦å‡å¤±æ•—ï¼ˆåƒè€ƒ `D:\MIAT\CLAUDE.md`ï¼‰

### 5.4 åˆ†æçµæœ

é»æ“Š **Analyze** å¾Œï¼Œæ‡‰è©²çœ‹åˆ°ï¼š

```
[Analyze Results]
âœ… Model validated successfully
âœ… Input shape: (1, 72, 36, 36) - 4D tensor
âœ… Output shape: (1, 1)
âœ… Total Memory: ~200-500 KB (depending on optimization)
âœ… RAM: ~150-300 KB
âœ… Flash: ~20-30 KB (INT8 weights)
```

**å¦‚æœå‡ºç¾éŒ¯èª¤**:
- âŒ "Unexpected combination of configuration and input shape" â†’ æ¨¡å‹ä»æ˜¯ 6Dï¼Œè«‹ç¢ºèªä½¿ç”¨ `rppg_4d_int8.onnx`
- âŒ "Unsupported operator" â†’ æª¢æŸ¥ opset ç‰ˆæœ¬ï¼ˆæ‡‰è©²æ˜¯ 13ï¼‰
- âŒ "Memory allocation failed" â†’ é™ä½å„ªåŒ–ç´šåˆ¥ï¼ˆO2 â†’ O1ï¼‰

### 5.5 ç”Ÿæˆä»£ç¢¼

1. é»æ“Š **Generate Code**
2. ç­‰å¾…ä»£ç¢¼ç”Ÿæˆå®Œæˆ
3. æ‰“é–‹ç”Ÿæˆçš„é …ç›®

---

## Step 6: é©—è­‰æ¨è«–

### 6.1 æº–å‚™æ¸¬è©¦æ•¸æ“š

åœ¨ STM32 æ‡‰ç”¨ä»£ç¢¼ä¸­ï¼Œéœ€è¦æº–å‚™ 4D è¼¸å…¥ï¼š

```c
// app_x-cube-ai.c

// è¼¸å…¥ç·©è¡å€: (1, 72, 36, 36) = 93,312 å€‹ int8 å€¼
static int8_t input_buffer[1 * 72 * 36 * 36];  // 93,312 bytes

// è¼¸å‡ºç·©è¡å€: (1, 1) = 1 å€‹ float32 å€¼
static float output_buffer[1];  // 4 bytes

void prepare_input_data() {
    // å¾æ”åƒé ­ç²å– 8 å¹€åœ–åƒï¼Œæ¯å¹€æå– 3 å€‹ ROI
    // æ¯å€‹ ROI æ˜¯ 36Ã—36Ã—3 (RGB)

    for (int t = 0; t < 8; t++) {          // 8 å€‹æ™‚é–“æ­¥
        for (int roi = 0; roi < 3; roi++) { // 3 å€‹ ROI
            for (int c = 0; c < 3; c++) {   // 3 å€‹é€šé“ (RGB)
                for (int h = 0; h < 36; h++) {
                    for (int w = 0; w < 36; w++) {
                        // è¨ˆç®—åœ¨ 4D å¼µé‡ä¸­çš„ç´¢å¼•
                        int channel_idx = t * 3 * 3 + roi * 3 + c;  // 0-71
                        int idx = channel_idx * 36 * 36 + h * 36 + w;

                        // å¡«å……æ•¸æ“šï¼ˆINT8 ç¯„åœ [-128, 127]ï¼‰
                        // å¯¦éš›æ‡‰å¾åœ–åƒæå–ä¸¦æ­£è¦åŒ–
                        input_buffer[idx] = (int8_t)((pixel_value - 128));
                    }
                }
            }
        }
    }
}

void run_inference() {
    // é‹è¡Œæ¨è«–
    ai_run(network, input_buffer, output_buffer);

    // è¼¸å‡ºå¿ƒç‡
    float heart_rate = output_buffer[0];  // 30-180 BPM
    printf("Heart Rate: %.2f BPM\n", heart_rate);
}
```

### 6.2 æ¸¬è©¦æ¨è«–

1. ç·¨è­¯é …ç›®
2. ç‡’éŒ„åˆ° STM32N6
3. é‹è¡Œæ¸¬è©¦
4. æª¢æŸ¥ log è¼¸å‡º

**æˆåŠŸæ¨™èªŒ**:
```
âœ… Network initialized
âœ… Inference completed
âœ… Heart Rate: 72.45 BPM
```

**å¤±æ•—æ¨™èªŒ**:
```
âŒ LL_ATON_RT_RunEpochBlock() returned 0 (ERROR)
âŒ Network initialization failed
```

å¦‚æœå¤±æ•—ï¼Œåƒè€ƒ `D:\MIAT\rppg\CLAUDE.md` çš„æ•…éšœæ’é™¤éƒ¨åˆ†ã€‚

---

## æ•…éšœæ’é™¤

### å•é¡Œ 1: STM32CubeMX Analyze éŒ¯èª¤

**éŒ¯èª¤**: "Unexpected combination of configuration and input shape"

**åŸå› **: ä»åœ¨ä½¿ç”¨ 6D ONNX æ¨¡å‹

**è§£æ±º**:
```bash
# æª¢æŸ¥æ¨¡å‹å½¢ç‹€
python -c "import onnx; m=onnx.load('rppg_4d_int8.onnx'); print([d.dim_value for d in m.graph.input[0].type.tensor_type.shape.dim])"

# æ‡‰è©²è¼¸å‡º: [0, 72, 36, 36]  ï¼ˆbatch=0 è¡¨ç¤ºå‹•æ…‹ï¼‰
# å¦‚æœæ˜¯ [0, 8, 3, 36, 36, 3] â†’ éŒ¯èª¤ï¼ä½¿ç”¨äº†èˆŠæ¨¡å‹
```

### å•é¡Œ 2: é‡åŒ–ç²¾åº¦å¤ªå·®

**ç—‡ç‹€**: MAE > 10 BPM

**è§£æ±º**:
1. å¢åŠ æ ¡æº–æ¨£æœ¬æ•¸é‡ï¼ˆ200 â†’ 500ï¼‰
2. ä½¿ç”¨çœŸå¯¦æ•¸æ“šè€Œééš¨æ©Ÿæ•¸æ“š
3. è€ƒæ…®ä½¿ç”¨ QDQ (Quantize-Dequantize) æ ¼å¼

### å•é¡Œ 3: æ¨è«–è¿”å›éŒ¯èª¤

**ç—‡ç‹€**: `LL_ATON_RT_RunEpochBlock()` è¿”å› 0

**è§£æ±º**:
1. **é™ä½å„ªåŒ–ç´šåˆ¥**: O3 â†’ O2 â†’ O1
2. **æª¢æŸ¥å…§å­˜é…ç½®**: ç¢ºä¿ AXISRAM è¶³å¤ 
3. **é©—è­‰è¼¸å…¥æ•¸æ“š**: ç¢ºä¿ INT8 ç¯„åœæ­£ç¢º
4. **åƒè€ƒ Zero-DCE ç¶“é©—**: è©³è¦‹ `D:\MIAT\CLAUDE.md`

---

## ç¸½çµ

### âœ… å®Œæˆæ­¥é©Ÿ

- [ ] Step 1: ä¸Šå‚³è…³æœ¬åˆ°æœå‹™å™¨
- [ ] Step 2: åŸ·è¡Œ `convert_to_4d_for_stm32.py` â†’ ç”Ÿæˆ `rppg_4d_fp32.onnx`
- [ ] Step 3: åŸ·è¡Œ `quantize_4d_model.py` â†’ ç”Ÿæˆ `rppg_4d_int8.onnx`
- [ ] Step 4: ä¸‹è¼‰ `rppg_4d_int8.onnx` åˆ°æœ¬åœ°
- [ ] Step 5: å°å…¥åˆ° STM32CubeMX (ä½¿ç”¨ O1 æˆ– O2)
- [ ] Step 6: ç”Ÿæˆä»£ç¢¼ä¸¦é©—è­‰æ¨è«–

### ğŸ¯ é—œéµè¦é»

1. **ä¸éœ€è¦é‡æ–°è¨“ç·´** - æ¬Šé‡å®Œå…¨ç›¸åŒï¼Œåªæ˜¯è¼¸å…¥å½¢ç‹€æ”¹è®Š
2. **éœ€è¦é‡æ–°å°å‡º ONNX** - å¾ 6D æ”¹ç‚º 4D
3. **éœ€è¦é‡æ–°é‡åŒ–** - åŸºæ–¼æ–°çš„ 4D ONNX
4. **é¿å…ä½¿ç”¨ O3 å„ªåŒ–** - æœƒå°è‡´ç·©è¡å€é‡ç–Šå•é¡Œ
5. **ä¿¡ä»»å·¥å…·çš„è‡ªå‹•é…ç½®** - ä¸è¦æ‰‹å‹•ä¿®æ”¹ç”Ÿæˆçš„ä»£ç¢¼

### ğŸ“š åƒè€ƒæ–‡æª”

- æœ¬æ–‡ä»¶: `D:\MIAT\rppg\DEPLOY_4D_TO_STM32.md`
- Zero-DCE ç¶“é©—: `D:\MIAT\CLAUDE.md`
- rPPG é …ç›®è¨˜éŒ„: `D:\MIAT\rppg\CLAUDE.md`

---

**æœ€å¾Œæ›´æ–°**: 2025-11-26
**ä½œè€…**: Claude Code AI
