# rPPG è¶…è½»é‡æ¨¡å‹è®­ç»ƒ - æœåŠ¡å™¨ç«¯å…¨æµç¨‹

å®Œæ•´çš„ rPPG (Remote Photoplethysmography) è®­ç»ƒæµç¨‹ï¼Œé’ˆå¯¹ STM32N6 éƒ¨ç½²ä¼˜åŒ–ã€‚

**æ‰€æœ‰æ­¥éª¤å‡åœ¨æœåŠ¡å™¨ç«¯è¿è¡Œï¼ˆæ— éœ€æœ¬åœ°é¢„å¤„ç†ï¼‰**

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
D:\MIAT\rppg\
â”œâ”€â”€ README.md                   # æœ¬æ–‡ä»¶
â”œâ”€â”€ CLAUDE.md                    # é¡¹ç›®æ–‡æ¡£ä¸å†å²è®°å½•
â”œâ”€â”€ model.py                     # æ¨¡å‹æ¶æ„å‚è€ƒ
â”‚
â””â”€â”€ server_training/             # âœ… æœåŠ¡å™¨ç«¯å·¥ä½œç›®å½•ï¼ˆä¸Šä¼ æ­¤æ–‡ä»¶å¤¹åˆ° serverï¼‰
    â”œâ”€â”€ download_ubfc.sh         # ä¸‹è½½ UBFC æ•°æ®é›†
    â”œâ”€â”€ preprocess_data.py       # æ•°æ®é¢„å¤„ç†
    â”œâ”€â”€ train.py                 # è®­ç»ƒä¸»è„šæœ¬
    â”œâ”€â”€ model.py                 # æ¨¡å‹å®šä¹‰
    â”œâ”€â”€ validate_data.py         # æ•°æ®éªŒè¯å·¥å…·
    â”œâ”€â”€ config.yaml              # è®­ç»ƒé…ç½®
    â”œâ”€â”€ requirements.txt         # Python ä¾èµ–
    â”œâ”€â”€ environment.yml          # Conda ç¯å¢ƒé…ç½®
    â”œâ”€â”€ setup_env.sh             # ç¯å¢ƒè®¾ç½®è„šæœ¬
    â”œâ”€â”€ run_training.sh          # è®­ç»ƒå¯åŠ¨è„šæœ¬
    â”œâ”€â”€ run_all.sh               # ä¸€é”®è¿è¡Œæ‰€æœ‰æ­¥éª¤
    â”‚
    â”œâ”€â”€ raw_data/                # åŸå§‹æ•°æ®é›†ï¼ˆä¸‹è½½åå­˜æ”¾ï¼‰
    â”‚   â””â”€â”€ UBFC-rPPG/
    â”‚       â””â”€â”€ subject*/
    â”‚
    â”œâ”€â”€ data/                    # é¢„å¤„ç†æ•°æ®
    â”‚   â”œâ”€â”€ ubfc_processed.pt
    â”‚   â””â”€â”€ dataset_info.json
    â”‚
    â”œâ”€â”€ checkpoints/             # è®­ç»ƒè¾“å‡º
    â”‚   â”œâ”€â”€ best_model.pth
    â”‚   â””â”€â”€ train_history.json
    â”‚
    â””â”€â”€ logs/                    # è®­ç»ƒæ—¥å¿—
        â””â”€â”€ train_*.log
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ç½®è¦æ±‚

- Linux æœåŠ¡å™¨ï¼ˆæ¨è Ubuntu 20.04+ï¼‰
- NVIDIA GPUï¼ˆæ¨è A6000ï¼Œè‡³å°‘ RTX 3090ï¼‰
- CUDA 12.1
- Conda / Miniconda
- çº¦ 10 GB ç£ç›˜ç©ºé—´

### ä¸€é”®è¿è¡Œï¼ˆæ¨èï¼‰

```bash
# 1. æ‹·è´é¡¹ç›®åˆ°æœåŠ¡å™¨
scp -r server_training username@server:/path/to/rppg_training/

# 2. SSH åˆ°æœåŠ¡å™¨
ssh username@server
cd /path/to/rppg_training/

# 3. è®¾ç½®ç¯å¢ƒ
bash setup_env.sh

# 4. ä¸€é”®è¿è¡Œæ‰€æœ‰æ­¥éª¤ï¼ˆä¸‹è½½ â†’ é¢„å¤„ç† â†’ è®­ç»ƒï¼‰
bash run_all.sh
```

**é¢„è®¡æ€»è€—æ—¶**: 4-6 å°æ—¶

---

## ğŸ“– è¯¦ç»†æ­¥éª¤

### Step 1: ä¸Šä¼ é¡¹ç›®åˆ°æœåŠ¡å™¨

```bash
# åœ¨æœ¬åœ° Windows æ‰§è¡Œ
cd D:\MIAT\rppg
scp -r server_training username@server_ip:/home/username/rppg_training/

# æˆ–ä½¿ç”¨ rsyncï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
rsync -avz --progress server_training/ username@server_ip:/home/username/rppg_training/
```

### Step 2: ç¯å¢ƒè®¾ç½®ï¼ˆä¸€æ¬¡æ€§ï¼‰

```bash
# SSH åˆ°æœåŠ¡å™¨
ssh username@server_ip
cd /home/username/rppg_training/

# è¿è¡Œè®¾ç½®è„šæœ¬
bash setup_env.sh
```

**è„šæœ¬å°†**ï¼š
- åˆ›å»ºç›®å½•ç»“æ„ï¼ˆraw_data/, data/, checkpoints/, logs/ï¼‰
- åˆ›å»ºåä¸º `rppg_training` çš„ conda ç¯å¢ƒ
- å®‰è£… PyTorch 2.1.0 + CUDA 12.1
- å®‰è£…æ‰€æœ‰ä¾èµ–ï¼ˆåŒ…æ‹¬ gdown ç”¨äºä¸‹è½½æ•°æ®é›†ï¼‰
- éªŒè¯å®‰è£…

### Step 3: ä¸‹è½½æ•°æ®é›†

```bash
conda activate rppg_training
bash download_ubfc.sh
```

**è¯´æ˜**ï¼š
- ä½¿ç”¨ `gdown` ä» Google Drive è‡ªåŠ¨ä¸‹è½½ UBFC-rPPG æ•°æ®é›†
- é¢„è®¡æ—¶é—´ï¼š30-60 åˆ†é’Ÿï¼ˆå–å†³äºç½‘é€Ÿï¼‰
- è¾“å‡ºï¼š`raw_data/UBFC-rPPG/subject01-43/`
- æ•°æ®é›†å¤§å°ï¼šçº¦ 5 GB

**å¦‚æœ gdown ä¸‹è½½å¤±è´¥**ï¼š
1. è®¿é—®ï¼šhttps://sites.google.com/view/ybenezeth/ubfcrppg
2. æ‰‹åŠ¨ä¸‹è½½æ•°æ®é›†åˆ°æœ¬åœ°
3. ä½¿ç”¨ scp ä¸Šä¼ åˆ°æœåŠ¡å™¨ï¼š
   ```bash
   scp -r UBFC-rPPG username@server:/path/to/rppg_training/raw_data/
   ```

### Step 4: æ•°æ®é¢„å¤„ç†

```bash
python preprocess_data.py --dataset ubfc --raw_data raw_data --output data
```

**è¯´æ˜**ï¼š
- ä½¿ç”¨ Haar Cascade æ£€æµ‹è„¸éƒ¨
- æå– 3 ä¸ª ROI åŒºåŸŸï¼ˆå‰é¢ã€å·¦è„¸é¢Šã€å³è„¸é¢Šï¼‰
- æ¯ä¸ª ROI è°ƒæ•´ä¸º 36Ã—36 åƒç´ 
- åˆ›å»ºæ—¶é—´çª—å£æ ·æœ¬ï¼ˆ8 å¸§/çª—å£ï¼‰
- é¢„è®¡æ—¶é—´ï¼š2-3 å°æ—¶ï¼ˆCPU å¯†é›†ï¼‰
- è¾“å‡ºï¼š`data/ubfc_processed.pt`ï¼ˆçº¦ 1.2 GBï¼‰

### Step 5: éªŒè¯æ•°æ®ï¼ˆå¯é€‰ä½†æ¨èï¼‰

```bash
# éªŒè¯åŸå§‹æ•°æ®
python validate_data.py --mode raw

# éªŒè¯é¢„å¤„ç†æ•°æ®
python validate_data.py --mode preprocessed

# éªŒè¯ä¸¤è€…
python validate_data.py --mode both
```

### Step 6: è®­ç»ƒæ¨¡å‹

```bash
bash run_training.sh
```

**è¯´æ˜**ï¼š
- ä½¿ç”¨ A6000 GPU è®­ç»ƒ
- Batch size: 128
- Epochs: 50 (with early stopping)
- é¢„è®¡æ—¶é—´ï¼š1.5-2 å°æ—¶
- è¾“å‡ºï¼š
  - `checkpoints/best_model.pth` - æœ€ä½³æ¨¡å‹
  - `checkpoints/train_history.json` - è®­ç»ƒå†å²
  - `logs/train_YYYYMMDD_HHMMSS.log` - è®­ç»ƒæ—¥å¿—

---

## ğŸ“Š æ¨¡å‹ä¿¡æ¯

### UltraLightRPPG (Multi-ROI ç‰ˆæœ¬)

- **æ¶æ„**: Shared 2D CNN (ç©ºé—´) + 1D Conv (æ—¶åº) + ROI Fusion
- **å‚æ•°é‡**: ~20Kï¼ˆæ¯”å• ROI ç‰ˆæœ¬å‡å°‘ 60%ï¼‰
- **è¾“å…¥**: (B, 8, 3, 36, 36, 3)
  - B: Batch size
  - 8: æ—¶é—´çª—å£ï¼ˆ8 å¸§ï¼‰
  - 3: ROI æ•°é‡ï¼ˆå‰é¢ã€å·¦è„¸é¢Šã€å³è„¸é¢Šï¼‰
  - 36Ã—36: å›¾åƒå°ºå¯¸
  - 3: RGB é€šé“
- **è¾“å‡º**: (B, 1) - BVP å€¼
- **è®°å¿†ä½“éœ€æ±‚**: ~80 KBï¼ˆæ¨¡å‹æƒé‡ï¼‰
- **é€‚åˆ**: STM32N6 éƒ¨ç½²

### ç½‘ç»œç»“æ„

```
Input (B, 8, 3, 36, 36, 3)
    â†“
Reshape â†’ (B*T*ROI, C, H, W) = (B*24, 3, 36, 36)
    â†“
Shared Spatial CNN (æ‰€æœ‰ ROI å…±äº«æƒé‡)
  - Conv2D(3â†’16) + BN + ReLU + MaxPool   (36Ã—36 â†’ 18Ã—18)
  - Conv2D(16â†’32) + BN + ReLU + MaxPool  (18Ã—18 â†’ 9Ã—9)
  - Conv2D(32â†’16) + BN + ReLU
  - AdaptiveAvgPool2d(1)                  (9Ã—9 â†’ 1Ã—1)
    â†“ (B*24, 16)
Reshape â†’ (B, T, ROI, 16) = (B, 8, 3, 16)
    â†“
ROI Fusion (Concatenation) â†’ (B, 8, 48)
    â†“
Transpose â†’ (B, 48, 8)
    â†“
Temporal Conv1D
  - Conv1D(48â†’32, k=3) + ReLU
  - Conv1D(32â†’16, k=3) + ReLU
    â†“ (B, 16, 8)
Flatten â†’ (B, 128)
    â†“
Fully Connected
  - Linear(128â†’32) + ReLU
  - Linear(32â†’1)
    â†“
Output (B, 1) - BVP value
```

---

## ğŸ”§ è‡ªå®šä¹‰é…ç½®

### ä¿®æ”¹è®­ç»ƒå‚æ•°

ç¼–è¾‘ `config.yaml`:

```yaml
# æ•°æ®è·¯å¾„
data_paths:
  - 'data/ubfc_processed.pt'

# è®­ç»ƒå‚æ•°
batch_size: 128         # å¯è°ƒæ•´ (64, 128, 256)
num_epochs: 50          # å¯è°ƒæ•´
learning_rate: 0.001    # å¯è°ƒæ•´
train_split: 0.8        # è®­ç»ƒ/éªŒè¯æ¯”ä¾‹

# Early stopping
early_stopping_patience: 5

# ç¡¬ä»¶
num_workers: 4
```

### ä¿®æ”¹æ¨¡å‹æ¶æ„

ç¼–è¾‘ `model.py` ä¸­çš„ `UltraLightRPPG` ç±»ã€‚

---

## ğŸ“ˆ ç›‘æ§è®­ç»ƒ

### æ–¹æ³• 1: æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶

```bash
tail -f logs/train_YYYYMMDD_HHMMSS.log
```

### æ–¹æ³• 2: ä½¿ç”¨ screen/tmuxï¼ˆæ¨èç”¨äºé•¿æ—¶é—´è®­ç»ƒï¼‰

```bash
# åˆ›å»ºæ–° session
screen -S rppg_training

# è¿è¡Œè®­ç»ƒ
bash run_all.sh

# åˆ†ç¦» session: Ctrl+A, D

# é‡æ–°è¿æ¥
screen -r rppg_training
```

---

## âœ… éªŒè¯ç»“æœ

è®­ç»ƒå®Œæˆåï¼Œæ£€æŸ¥ï¼š

1. **æœ€ä½³æ¨¡å‹**: `checkpoints/best_model.pth`
2. **è®­ç»ƒå†å²**: `checkpoints/train_history.json`
3. **æ—¥å¿—æ–‡ä»¶**: `logs/train_YYYYMMDD_HHMMSS.log`

### é¢„æœŸæ€§èƒ½

åŸºäº UBFC æ•°æ®é›†ï¼š
- **MAE**: 3-5 BPMï¼ˆç›®æ ‡ï¼‰
- **RMSE**: 4-6 BPM
- **MAPE**: 5-10%

### ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°

```bash
# åœ¨æœ¬åœ°æ‰§è¡Œ
scp username@server:/path/to/rppg_training/checkpoints/best_model.pth .
```

---

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜ 1: gdown ä¸‹è½½å¤±è´¥

```
Error: Cannot download from Google Drive
```

**è§£å†³**ï¼š
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. ä½¿ç”¨å¤‡ç”¨ä¸‹è½½æ–¹æ³•ï¼ˆè§ Step 3ï¼‰
3. æˆ–ä½¿ç”¨ `rclone`:
   ```bash
   rclone copy "drive:UBFC-rPPG" raw_data/UBFC-rPPG/ --progress
   ```

### é—®é¢˜ 2: CUDA Out of Memory

```
RuntimeError: CUDA out of memory
```

**è§£å†³**ï¼šé™ä½ batch size
```yaml
# config.yaml
batch_size: 64  # æˆ–æ›´å°
```

### é—®é¢˜ 3: Haar Cascade æ–‡ä»¶ç¼ºå¤±

```
Error: haarcascade_frontalface_default.xml not found
```

**è§£å†³**ï¼š
```bash
# éªŒè¯æ–‡ä»¶
python -c "import cv2; print(cv2.data.haarcascades)"

# å¦‚æœä¸å­˜åœ¨ï¼Œæ‰‹åŠ¨ä¸‹è½½
wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml
```

### é—®é¢˜ 4: æ•°æ®é›†æœªæ‰¾åˆ°

```
Error: UBFC directory not found
```

**è§£å†³**ï¼šç¡®è®¤ç›®å½•ç»“æ„
```bash
ls raw_data/UBFC-rPPG/
# åº”è¯¥çœ‹åˆ° subject1, subject2, ... subject43
```

### é—®é¢˜ 5: ç¯å¢ƒåˆ›å»ºå¤±è´¥

```
Error: Could not create conda environment
```

**è§£å†³**ï¼šæ‰‹åŠ¨å®‰è£…
```bash
conda create -n rppg_training python=3.12.3
conda activate rppg_training
pip install -r requirements.txt
```

---

## ğŸ“ æ³¨æ„äº‹é¡¹

### èµ„æºéœ€æ±‚
- **ç£ç›˜ç©ºé—´**: çº¦ 10 GB
  - åŸå§‹æ•°æ®ï¼š~5 GB
  - é¢„å¤„ç†æ•°æ®ï¼š~1.2 GB
  - æ¨¡å‹å’Œæ—¥å¿—ï¼š~100 MB
  - å‰©ä½™ç¼“å†²ï¼š~4 GB
- **å†…å­˜**: è‡³å°‘ 16 GB RAM
- **GPU**: è‡³å°‘ 8 GB VRAMï¼ˆæ¨è 24 GBï¼‰

### æ—¶é—´æˆæœ¬
| é˜¶æ®µ | æ—¶é—´ | ç¡¬ä»¶ |
|------|------|------|
| ä¸‹è½½æ•°æ® | 30-60 åˆ†é’Ÿ | ç½‘ç»œ |
| é¢„å¤„ç† | 2-3 å°æ—¶ | CPU |
| è®­ç»ƒ | 1.5-2 å°æ—¶ | GPU |
| **æ€»è®¡** | **4-6 å°æ—¶** | |

### Multi-ROI ç‰¹æ€§
- ä½¿ç”¨ 3 ä¸ª ROI åŒºåŸŸæå‡å‡†ç¡®åº¦
- æ¯ä¸ª ROI ç‹¬ç«‹å¤„ç†åèåˆ
- å‚æ•°é‡å‡å°‘ä½†å‡†ç¡®åº¦æå‡
- æ›´é€‚åˆ STM32N6 éƒ¨ç½²

---

## ğŸ“ ä¸‹ä¸€æ­¥

è®­ç»ƒå®Œæˆåï¼š
1. âœ… ä¸‹è½½ `checkpoints/best_model.pth` å›æœ¬åœ°
2. è½¬æ¢ä¸º ONNX æ ¼å¼
   ```python
   import torch
   model.eval()
   dummy_input = torch.randn(1, 8, 3, 36, 36, 3)
   torch.onnx.export(model, dummy_input, "rppg_model.onnx")
   ```
3. ä½¿ç”¨ X-CUBE-AI è½¬æ¢ä¸º STM32 æ ¼å¼
4. éƒ¨ç½²åˆ° STM32N6

---

## ğŸ“š å‚è€ƒèµ„æ–™

- **UBFC-rPPG**: https://sites.google.com/view/ybenezeth/ubfcrppg
- **PyTorch**: https://pytorch.org/
- **X-CUBE-AI**: https://www.st.com/en/embedded-software/x-cube-ai.html
- **é¡¹ç›®æ–‡æ¡£**: å‚è§ `CLAUDE.md`

---

**ç‰ˆæœ¬**: 2.0 - æœåŠ¡å™¨ç«¯å…¨æµç¨‹
**æ—¥æœŸ**: 2025-11-18
**æ›´æ–°**: ä»"æœ¬åœ°é¢„å¤„ç†+æœåŠ¡å™¨è®­ç»ƒ"è¿ç§»åˆ°"çº¯æœåŠ¡å™¨ç«¯"æ¶æ„
